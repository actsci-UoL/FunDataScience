# Getting started with R {#Wk1}

## Overview

### Objectives

On successful completion of this module, you should be able to:

  - Define data science and discuss its role in actuarial science and business analytics
  - Create and run simple program scripts in the RStudio environment and read data into R from a local tabular file
  - Create and share literate programs and reports using R Markdown and undertake simple EDA (including summary statistics and informative visualisations) of data in a tabular structure
  - Implement a reproducible workflow for simple data science project and describe ethical and regulatory issues to be considered when undertaking a data science project

I prefer an alternative statement of the objectives:

By the end of this module you will be confident in handling data in a collaborative and reproducible way. In other words in a __professional__ way. You will be able to:

  - get
  - clean
  - check
  - restructure
  - filter, sort, join & summarise
  - explore
  - visualise...
  
...data

The specific objectives for this week are:

1. Be able to access your R Server account
2. Successfully upload Task 1 from Blackboard to the server
3. Complete the exercises in the Week 1 task
4. Knit to HTML and download HTML and RMD files
5. Submit RMD and HTML files for feedback on Blackboard

### Problem-based learning

The structure of this module may be a bit different to what you have come across before.

In a "traditional" university lecture you arrive without having done any preparation, the lecturer gives you some information, and you go away to try and absorb it and probably do some exercises or homework.

In a "flipped" classroom you are supposed to have done reading, or used other resources, so that you have some familiarity with the material before the class. In class you focus on applying what you have learnt to some exercises.

This module is quite similar to a flipped classroom, but here, working on the task and learning what you need to successfully complete it will happen much more in parallel. I will give you a quick overview of some of the things you need to know each week, and there will be some indicative reading. But after that it is up to you (usually working as part of a team) to work out a good solution to the task.

This is much more like the way things happen in real life.
  
### Introductions
  - Dr Paul King FIA (Lecturer)
    + paul.king@leicester.ac.uk
    + No set office hours: email for an appointment
  - Your friendly TAs
    + Ahmed Dogar - ajd67.le.ac.uk
    + Ibrahim Issahaku - iai5@le.ac.uk
    + Daniel Lozano Rojas - dlr10@le.ac.uk


### Class times

  - Tuesday 13:00 - 14:00, Attenborough Building Lecture Theatre 1
  - Wednesday 12:00 - 13:00, On-line - see the Teams invite on Blackboard
  - Thursday 13:00 - 14:00, Various computer labs
  
### How this module works

  - A certain amount of lecturing (mostly on Tuesdays)
  - A lot of group problem solving (mostly on Wednesdays and Thursdays)
  - A lot of self study: using the reading list and other on-line resources
  - Additional resources:
    + Data Science Club (if you want to run one!)
    + DataCamp
  - The weekly tasks for an important part of the learning activity on this module and the completed tasks will be a key part of the set of notes you develop
    
### Group working

From next week you will be working in groups on a weekly coding task. The output will be a R Markdown notebook containing your code and results - each member of the group must produce their own notebook and be able to edit it and run it on the server or their own machine. Completed tasks (i.e. the PDF file) should be submitted by midnight on Sunday (UK time) in the week of the class.

### Getting help on the weekly task

You can ask for help from your TA during the Wednesday computer lab. Outside of the lab (or even inside) you can post questions on the Blackboard discussion forum. Try to formulate your question as specifically as possible and give a code sample. That way the question can be answered in the thread and benefit everybody (other students are encouraged to answer questions). If you need more detailed help a TA will contact you via Teams.

I'll create a separate chat for general questions about the course. Please try to put as many of your questions here as possible so everyone can benefit, but if it's something a bit more personal, please feel free to email me (paul.king@leicester.ac.uk) directly. I'm happy to arrange a one to one meeting over Teams or face to face.

### Submitting the weekly task

When you've completed the weekly task, please submit both your RMD and HTML files via the assignment links on Blackboard (to be set up).

Each exercise in the task will be graded on the following scale:

0. Nothing (significant) submitted
1. Exercise attempted but not working / incomplete
2. Nearly there
3. Full correct answer (note, there is no single correct answer)

These are designed to be a quick and easy way of giving feedback and allowing me to check that everyone is progressing OK. These "marks" will not count towards your final assessment for the module.
    
### DataCamp

You have been sent an invitation email and there is more information in [Getting Set Up](#datacamp1).

It's a very good idea to take advantage of this resource while it's available.


### Data Club

  - Chance to practice and develop Data Science Skills in an informal atmosphere
  - First meeting is Thursday  13 October 2022 at 17:00 (Teams meeting on Blackboard)
  - The idea is to meetup and work on a data task collaboratively to develop skills
  - I'll host the initial meeting, but after that it will need to be run by you, so volunteers are needed.
  - More info at Thursday's meeting

### How this module is assessed

  - Coursework mid-semester (30%)
    + similar to problems solved in class; but
    + you must work on your own
    + available at the end of week 15 and due in two weeks later
  - Final report and presentation (70%)
    + you will work on a group data science project and produce both a detailed report of the analysis and a presentation
    + the presentation must include slides (generated from R markdown) but they will be marked on the submitted document - you will not be required to give a stand up presentation
    + each individual will have to identify an aspect they worked on, for questions
    + some of the marks will be for demonstrating knowledge of the topics in the lectures after revision week
    + assessments for MA3419 and MA7419 are different
  - Weekly Blackboard quiz
    + Each week there will be a Blackboard quiz asking if you feel you have achieved the specified objectives for that week. This is a chance to reflect on your work over the week and thereby reinforce your learning
- more details will be given when the first coursework is made available
    
## Reading

R for Data Science [@wickhamR4DS]:

  - Chapter 4 _Workflow: basics_

R Programming for Data Science [@pengRP4DS]:

  - Chapter 13 _R nuts & bolts_


## Reproducible data science

### Introduction

We are going to discuss _Reproducible Data Science_. This is often referred to as _Reproducible Research_, but it applies to lots of data science activities we might not consider as research.

It's helpful to consider the process of data science, for example as illustrated by Roger Peng in his book _Report Writing for Data Science in R_ [@pengRWDSR].

![](Images/DataSciencePipeline.png)


---
The steps in the shaded box start with the raw (measured) data and end with the computational results. In this module we'll be concerned with these steps - the core of a reproducible pipeline - plus the presentation code used to produce the final output.

In this diagram _analytic data_ refers to the raw data after it has been checked, cleaned and reshaped into the right format for further analysis.

### What is Reproducible Data Science?

A reproducible data science process allows a reviewer or subsequent user of the work to reproduce the analysis __at least__ from the analytic data to the computational results. It should also allow them to: 

  - see what has been done at each stage;
  - understand the reasons for the decisions made at each step;  
  - check that the claimed steps have been carried out correctly.
  
In all but the simplest of projects, this requires the publication of well written, and well documented, code.

When we consider published work in the context of a scientific publication, reproducibility, as a minimum, requires making available the analytic data, code and details of the computational environment used.

However, it's important the the whole process, including pre-processing the data and producing the final outputs, is fully documented.

### Benefits (and disadvantages) of Reproducible Data Science

__Scientific:__

  - Replication of published work is a key element of the scientific process: reproduction of the analysis of data analysis is often the closest to replication it's realistically possible;
  - attempts at reproduction can reveal errors with potentially serious consequences.
  
__Professional:__

  - Ability to reproduce a workflow is key to checking for errors;
  - Documentation of data analysis is required for work review and auditability;
  - For actuaries, the professional standards APS X2 and APS QA2 require consideration to be given to reproducibility in relation to the above points;
  - A reproducible work flow allows efficient reuse or modification of an analysis pipeline.
  
__Personal:__

  - The next user of your work is most likely to be you!
  - the process of making your work reproducible requires you to stop (or at least slow down) occasionally to make sure you are working effectively and efficiently.

### How to make sure your work is reproducible

  - Create a consistent filing structure for data, code, intermediate and final results;
    + see the next section
  - Use RStudio and `knitr` to practice _literate programming_ by creating R Markdown notebooks;
  - Resist the temptation to do things manually - do as much programmatically as possible
    + coding all your data manipulation is not just about automating it, it's about documenting what you've done so it can be reproduced;
  - Comment code appropriately;
  - Stick to a coding standard (style guide)
    + we will use the [tidyverse style guide](https://style.tidyverse.org/){target="_blank"}
  - Save as few intermediate results as possible;
  - Use [version control](https://www.atlassian.com/git/tutorials/what-is-version-control){target="_blank"};
  - Keep track of your [programming environment](https://rstudio.github.io/packrat/){target="_blank"}
  
The last two points are important, but we don't have the time to go into them in any detail in this course.

### Further Reading

[APS X2 Review of Actuarial Work
](https://www.actuaries.org.uk/system/files/documents/pdf/20150122-aps-x2-final-version.pdf){target="_blank"}

[APS QA1 Quality Assurance for Organisations (Version 2.0)
](https://ifoa-www.s3.eu-west-2.amazonaws.com/live/s3fs-public/Updated%20APS%20QA1%20-%20V2.pdf){target="_blank"}

The Institute and Faculty of Actuaries has written about how [important Data Science is to the profession](https://www.actuaries.org.uk/learn-and-develop/lifelong-learning/what-data-science-actuarial-viewpoint).

## More resources

The Bookdown [home page](https://bookdown.org/) gives you access to many very good books covering different aspects of data science with R.

## Setting up your R environment.

You will be working in R every week during this module, so the first task is to make sure you have access to RStudio.

The next step is to configure your environment in a standard way so it will be relatively straightforward for us all to work share code and work together.

Go ahead and:

  1. Use RStudio to create a project called MA3419 or MA7419
  2. Inside that project, create folders for each Week during the Semester, plus a folder called _Data_
     + here is a [video](https://leicester.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=a931bb2f-51a6-4bbb-8416-ac490107e8b4) demonstrating how to do steps 1 & 2.
  3. Install the packages 'tidyverse' and 'here'
     + [video](https://leicester.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=faf773d1-fafa-42cd-8792-ac490114e4c7) demonstration
  4. Get familiar with the RStudio interface
     + [video](https://leicester.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=e7c41922-25d1-4eb3-b675-ac49010cd60e)
  5. Get familiar with the R Markdown notebook structure and how to run code inside a notebook
     + [video](https://leicester.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=195a932e-4a87-49a4-8f3b-ac4a00da319d)
     + I highly recommend this [blog article](https://statsandr.com/blog/getting-started-in-r-markdown/)
     + if you need more help, you'll almost certainly find something at [RStudio](https://education.rstudio.com/learn/beginner/){target="_blank"}
     + once you're reasonably familiar with RStudio and R Markdown have a look at some more advanced [Tips and Tricks](https://www.rstudio.com/blog/r-markdown-tips-tricks-2-cleaning-up-your-code/){target="_blank"} (This won't make much sense if you're an absolute beginner, but you should bookmark it and come back to it later.)

## Week 1 Task

Every week there will be a task provided as a .RMD file in the Blackboard folder. You need to copy this file into the appropriate week's folder in your MA3419/MA7419 folder and have it open in a running R session during the Wednesday class. The task files will become available on Monday mornings.

:::{.callout-note}
The marks for the weekly task are for feedback only. They don't count towards your module assessment.
:::

Sometimes there will also be a data file supplied - you should copy this into your project's Data folder.

Usually I'll work through parts of the task during the Wednesday class. There will also be embedded exercises for you to complete.

Your target should be to successfully complete all the exercises each week, and submit to your TA for feedback.

Occasionally there will be _challenge exercises_ or _challenge tasks_ - these are optional.